[TOC]

# 开源项目*pycorrector*分析

## 基于规则的方法

- `__init__.py`:
  - 构造了用于纠错的类`Corrector`，初始化了一些可直接调用的方法
  - 关于**检测**的方法：
    - `detect()`：检测句子中的疑似错误信息，包括[词、位置、错误类型]
    - `set_custom_confusion_dict()`：设置自定义混淆集
    - `set_custom_word()`：自定义切词词典
    - `set_language_model_path()`：设置语言模型路径并加载
    - `ngram_score()`：取n元文法得分
    - `ppl_score()`：取语言模型困惑度得分，越小句子越通顺
    - `word_frequency()`：取词在样本中的词频
    - `enable_char_error()`：字符错误检测是否打开
    - `enable_word_error()`：单词错误检测是否打开
  - 关于**纠正**的方法：
    - `get_same_pinyin()`：取同音字
    - `get_same_stroke()`：取形似字
    - `correct()`：句子改错
- `config.py`：
  - **数据的配置**，包括：通用分词词典文件，中文常用字符集，同音字，形似字，语言模型，知名人名词典，地名词典，停用词，用户自定义错别字混淆集，用户自定义分词词典，RNN语言模型
- `detector.py`：
  - 包括两个类，一个是`ErrorType()`，用于定义错误类型的数字表示；另一个是`Detector()`，如下所示
  - 类`Detector()`，用于检测
    - `initialize_detector()`：加载lm、词频词典、自定义词频词典、自定义混淆集、人名、地名、停用词，然后合并成一个词典为`self.word_freq`
    - `detect()`：检测句子中的疑似错误信息，包括[词、位置、错误类型]
- `corrector.py`：
  - 类`Corrector()`是`detector.py`的子类，用于纠错
    - `initialize_corrector()`：加载字符集、同音字集、形似字集
    - `generate_items()`：生成纠错候选集
    - `lm_correct_item()`：通过语言模型纠正字词错误
    - `correct()`：对输入句子进行改错
- `tokenizer.py`：
  - `segment()`：用于分词
  - 类`Tokenizer()`：
    - `__init__()`：加载大词典、自定义词典、混淆集词典
    - `tokenize()`：切词并返回切词位置
- `eval.py`：
- `en_spell`：英文拼写矫正器

## 基于深度模型的方法

使用了8种深度模型：

- kenlm：kenlm统计语言模型工具
- rnn_lm：TensorFlow、PaddlePaddle均有实现栈式双向LSTM的语言模型
- rnn_attention模型：参考Stanford University的nlc模型，该模型是参加2014英文文本纠错比赛并取得第一名的方法
- rnn_crf模型：参考阿里巴巴2016参赛中文语法纠错比赛并取得第一名的方法
- seq2seq模型：使用序列模型解决文本纠错任务，文本语法纠错任务中常用模型之一
- seq2seq_attention模型：在seq2seq模型加上attention机制，对于长文本效果更好，模型更容易收敛，但容易过拟合
- transformer模型：全attention的结构代替了lstm用于解决sequence to sequence问题，语义特征提取效果更好
- bert模型：中文fine-tuned模型，使用MASK特征纠正错字