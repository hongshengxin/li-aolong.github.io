[TOC]

# seq2seq相关学习

> 今天花费了较多的时间尝试运行昨天的开源代码，但因为源代码中pytorch版本太旧，fairseq工具，运行系统等问题没有成功，于是进行了seq2seq相关的学习

## 单层网络

对于单层网络，输入是x，经过变换Wx+b和激活函数f得到输出y

![img](https://pic1.zhimg.com/v2-da9ac1b5e3f91086fd06e6173fed1580_b.jpg)

## 经典的RNN结构（N vs N）

在实际应用中，有很多序列形的数据，序列形的数据不太好用原始的神经网络处理了。为了建模序列问题，RNN引入了隐状态h(hidden state)的概念，h可以对序列形的数据提取特征，接着再转换为输出。

从h1的计算开始看：

![img](https://pic1.zhimg.com/v2-a5f8bc30bcc2d9eba7470810cb362850_b.jpg)

图示中记号的含义是：

- **圆圈或方块表示的是向量**
- **一个箭头就表示对该向量做一次变换。如上图中h0和x1分别有一个箭头连接，就表示对h0和x1各做了一次变换**

h2的计算和h1类似，在计算时，**每一步使用的参数U、W、b都是一样的，也就是说每个步骤的参数都是共享的**

![img](https://pic3.zhimg.com/v2-74d7ac80ca83165092579932920d0ffe_b.jpg)

依次计算其余输入（使用相同的参数U、W、b）：

![img](https://pic2.zhimg.com/v2-bc9759f8c642208a0f8514ccd0260b31_b.jpg)

得到输出值的方法就是直接通过h进行计算：

![img](https://pic1.zhimg.com/v2-9f3a921d0d5c1313afa58bd3ef53af48_b.jpg)

**一个箭头表示对对应的向量做一次类似于f(Wx+b)的变换，这里的这个箭头就表示对h1进行一次变换，得到输出y1。**

剩下的输出类似进行（使用和y1同样的参数V和c）：

![img](https://pic2.zhimg.com/v2-629abbab0d5cc871db396f17e9c58631_b.jpg)

它的输入是x1, x2, .....xn，输出为y1, y2, ...yn，也就是说，**输入和输出序列必须要是等长的**。由于这个限制的存在，经典RNN的适用范围比较小

## Seq2Seq模型

又叫Encoder-Decoder模型，原始的N vs N RNN要求序列等长，然而我们遇到的大部分问题序列都是不等长的，如机器翻译中，源语言和目标语言的句子往往并没有相同的长度

**为此，Encoder-Decoder结构先将输入数据编码成一个上下文向量c：**

![img](https://pic2.zhimg.com/v2-03aaa7754bb9992858a05bb9668631a9_b.jpg)

得到c有多种方式，最简单的方法就是把Encoder的最后一个隐状态赋值给c，还可以对最后的隐状态做一个变换得到c，也可以对所有的隐状态做变换。

**得到c之后，就用另一个RNN网络对其进行解码**，这部分RNN网络被称为Decoder。具体做法就是将c当做之前的初始状态h0输入到Decoder中：

![img](https://pic4.zhimg.com/v2-77e8a977fc3d43bec8b05633dc52ff9f_b.jpg)

还有一种做法是将c当做每一步的输入

![img](https://pic4.zhimg.com/v2-e0fbb46d897400a384873fc100c442db_b.jpg)

由于这种Encoder-Decoder结构不限制输入和输出的序列长度，因此应用的范围非常广泛，比如：

- 机器翻译。Encoder-Decoder的最经典应用，这一结构就是在机器翻译领域最先提出的
- 文本摘要。输入是一段文本序列，输出是这段文本序列的摘要序列。
- 阅读理解。将输入的文章和问题分别编码，再对其进行解码得到问题的答案。
- 语音识别。输入是语音信号序列，输出是文字序列。

## Attention机制

在Encoder-Decoder结构中，Encoder把所有的输入序列都编码成一个统一的语义特征c再解码，**因此， c中必须包含原始序列中的所有信息，它的长度就成了限制模型性能的瓶颈。**如机器翻译问题，当要翻译的句子较长时，一个c可能存不下那么多信息，就会造成翻译精度的下降。

Attention机制通过在每个时间输入不同的c来解决这个问题，下图是带有Attention机制的Decoder：

![img](https://pic2.zhimg.com/80/v2-8da16d429d33b0f2705e47af98e66579_hd.jpg)

每一个c会自动去选取与当前所要输出的y最合适的上下文信息。具体来说，用aij衡量Encoder中第j阶段的hj和解码时第i阶段的相关性，最终Decoder中第i阶段的输入的上下文信息ci就来自于所有hj对aij的加权和。

机器翻译为例（将中文翻译成英文）：

![img](https://pic1.zhimg.com/80/v2-d266bf48a1d77e7e4db607978574c9fc_hd.jpg)

输入的序列是“我爱中国”，因此，Encoder中的h1、h2、h3、h4就可以分别看做是“我”、“爱”、“中”、“国”所代表的信息。在翻译成英语时，第一个上下文c1应该和“我”这个字最相关，因此对应的a11就比较大，而相应的a12、a13、a14就比较小。c2应该和“爱”最相关，因此对应的 a22就比较大。最后的c3和h3、h4最相关，因此 a33、a44的值就比较大。





