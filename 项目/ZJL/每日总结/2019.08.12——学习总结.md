[TOC]

# 学习总结

## 1 方法

总结了以下若干个用于GEC的模型：

- 语言模型：低概率序列比高概率序列更可能包含语法错误

- SMT与NMT混合模型
- seq2seq模型
  - 基于流畅度增强学习和推断机制
  - 使用attention机制的
- LSTM模型
  - 将CGED问题视为序列表及问题；使用双向LSTM单元；特征工程
- GRU模型
  - 基于context2vec；双向门控循环单元
- 其它
  - 数据增强：维基百科的修改记录；回环翻译

## 2 开源项目

以下两个项目内容较为齐全，同时代码量也较多

- pycorrector
  - 具有多个模型实现
  - 包括统计语言模型；栈式双向LSTM的语言模型；基于attention，crf的RNN模型；基于attention的seq2seq模型；transformer模型；bert模型；基于fairseq的卷积模型
- zlyang-master-dissertation-code
  - 基于卷积编解码网络的中文校对模型
  - 基于集成解码和重排序的中文文本自动校对
  - 基于多通道融合与重排序的中文文本自动校对

## 3 思路

- 将以上了解到的模型和两个开源项目进行融合
- 花费一定的时间进行代码的阅读与理解
- 对以上模型的实现逐步添加到开源项目中
- 以上模型与项目多为语法纠错，数据集也只有一小部分的金标准，直接使用在语音识别后的文本上效果未知，也没有评判标准

