# 文本纠错概述

## 1 简介

纠错技术相对于词法分析，句法分析等受到的**关注一直较小**，一方面是因为**文本出错的比例比较小**，在一些重要场合，也有专门人员进行校验；另一方面本身问题也相对较难，其要求计算机对语言规则以及文本语义有**深刻的理解**。

在 2000 年以前，业界主要依靠长期积累的**纠错规则**和**纠错词典**来进行纠错，比如微软的文档编辑产品 WORD 即采用这种方法。随着机器学习技术的发展，纠错问题受到了学术界和工业界越来越多的关注，其中有两大主流方法：一种解决思路是将语言错误归类，然后采用最大熵、SVM 等**分类方法**对这些类别进行重点识别；另外一种思路是借鉴**统计机器翻译**（SMT）的思想，将语言纠错等价为机器翻译的过程，即错误文本翻译为正确文本，并随之出现了一系列的优化方法。最近几年，随着**神经机器翻译**（NMT）技术的快速发展，人们逐步将 SMT 与 NMT 技术结合起来解决纠错问题。最近几年中文纠错的研究也得到较多的关注和发展，并陆续举办了几届中文纠错评测，例如 CGED 与 NLPCC 等。

目前，基于机器翻译的方法已经成为文本纠错的主流技术，主要思想是把纠错看成同种语言中错误句子翻译为正确句子的过程，其核心由**语言模型**和**翻译模型**组成。语言模型学习语言规则、语言知识；翻译模型从平行语料中学习用户的纠错行为。

SMT 纠错一般的典型做法：首先基于平行语料训练对齐模型，得到多粒度（字、词、音、形、短语）的混淆矩阵（Phrase Table）；针对具体的纠错实例，基于句子中的错误点从 Phrase Table 中召回可能的正确候选，然后基于句子语义理解，对这些纠错候选进行排序，从而得到正确的结果。而 NMT 方法主要依赖于大规模的监督语料，忽略掉中间的各种步骤，直接实现端到端的学习。NMT 方法相对于 SMT 方法的优势在于避免了 SMT 每一步过程中导致的错误传递，同时具有更强大的学习能力。

## 2 中英文相关研究

### 2.1 英文相关研究

^[1]^语法错误纠正是2013年第17届计算自然语言学习会议（**CoNLL-2013**）的共享任务。在此任务中，给定一个由英语学习者作为第二语言撰写的英语作文，目标是检测并纠正该作文中存在的语法错误，并返回经过更正的作文。以前的CoNLL共享任务侧重于自然语言处理的特定子任务（例如，命名实体识别，语义角色标签，依赖项解析或共指解析）。CoNLL-2013的共享任务有全球17个团队的参与，在语法错误纠正系统的准确性以及在处理更广泛的错误类型集的系统范围方面，还有很大的改进空间。

^[2]^与CoNLL-2013共享任务相比，**CoNLL-2014**中引入了以下更改：（1）参与系统将检测和纠正**所有类型的语法错误**，而不仅仅是CoNLL-2013中的五种错误类型; （2）将评估标准从F1更改为F0.5，以强调召回率的精度；（3）与CoNLL-2013中只有一名人类注释者相比，CoNLL-2014有两名人类注释者独立地对测试文章进行注释。CoNLL-2014中有13个队伍提交了系统，针对非特定错误矫正，基于语言模型(LM)的方法最为流行，但全部是混合模型。纠正所有错误的方案是使用基于短语的统计机器翻译(MT)系统，各队伍在微调方面不同。没有队伍使用基于语法的翻译模型，除了UMC在分解翻译模型中使用了词性标签。对于纠正单一错误类型，基于规则(RB)的方法很常见。语法错误纠正系统的准确性仍有很大的改进空间。

^[3]^该文章**混合**了SMT和NMT两种方法来进行GEC处理，得到的混合系统保留了SMT输出的准确性，同时产生了NMT典型的流畅语言。在CoNLL-2014的M2指标和JFLEG的GLEU指标下分别取得了50.19和56.74的结果，与其他GEC系统相比，该系统更接近达到人类水平。

^[4]^该文章使用全新的基于**流畅度增强学习**和**推断机制**(fluency boost learning and inference mechanism)的**seq2seq模型**来进行GEC处理，在CoNLL-2014的M2F0.5指标和JFLEG的GLEU指标下分别取得了75.72和62.42的结果，在这两个基础上首次超越人类。

^[5]^由于缺乏丰富的并行数据，本文描述了两种使用公共维基百科数据，为GEC**生成大型并行数据集**的方法。使用来自于维基百科的历史修改记录作为增广的语料。使用来自于回环翻译(RTT)的语料。从维基百科中提取目标句子，将其翻译成一种语言再翻译回来，可以得到相对干净的错误。语料库比人工导出的维基百科语料库的噪音小得多。但不同于人类错误，它产生的错误范围较小。在Lang-8语料库上的微调和集合模型使得本文超越了CoNLL-2014基准和JFLEG任务，语料增广技术对于模型在低资源任务上的效果提升有着非常重要的影响。

^[6]^将纠错视为分类问题，使用**双向门控循环单元**(GRUs)表示上下文，无需特征工程，在CoNLL-2014上达到SOTA。提出了一种新的神经网络架构来学习上下文表示，并用于GEC，其性能超过其它SOTA。该模型不需要复杂的特征工程，因为上下文特征表示可以由分类器以端到端的形式进行学习。计划注意力机制引入该模型，从而使得模型能够仅仅关注到影响语法的上下文单词。

^[7]^自CoNLL-2014结束以来，对基于语言模型(LM)的GEC方法的研究基本停滞不前。本文表明了仅使用最少的注释数据，完全有可能建立一个简单的系统，且可以获得有竞争力的结果。相比之下，SMT和其它是需要大量标记数据的方法无法实现这一点. 本文证明了在本文系统收到可纠正错误类型范围的限制下，使用最少注释数据的GEC**简单语言模型**方法仍然可以与依赖于大量注释训练数据的最新神经和机器翻译方法竞争

### 2.2 中文相关研究

中文没有单复数变化，动词的时态变化，结构松散，短句较多，从句较少。与英语相比，中文语法错误检测的研究要少得多，而且缺乏大量公开发布的数据也阻碍了其研究。中文拼写检查与其它字母语言有很大不同，单词之间没有分隔符，单词长度很短。

^[8]^2012年，Yu等人提出了一种**基于CRF的分类器**来检测**单词排序错误**，实验结果表明将句法特征，网络语料库特征和摄动特征相结合可用于词序错误检测。

^[9]^2014年，Cheng等人提出了一种可以自动检测是否存在语法错误并识别其错误类型的方法，该方法的框架是**基于规则的数据库方法**来识别常见的语法错误，包含了手动构建的规则和由程序自动生成的规则。

^[10][11][12][13]^NLPTea 2014/2015/2016/2018 CGED的共享任务旨在识别汉语学习者写撰写的句子中的**语法错误类型**，出现范围以及建议的更正，描述了任务定义，数据准备，性能指标和评估结果。

^[14]^提出了基于**字符嵌入双字嵌入的CRF+BiLSTM模型**，在NLP-TEA-3共享任务的CGED-HSK数据集上，该系统在所有三个级别中均显示了最佳的F1得分，并且在最近两个级别中均显示了最佳的召回率。

^[15]^本文结合了一些手工特征，如POS，依赖性特征，PMI分数等来训练**LSTM-CRF模型**，在精度，召回率和F1分数上达到最佳。未来希望基于seq2seq等模型直接纠正错误，通过结合预训练语言模型和其他相关的多任务模型来获得端到端语法错误识别系统。

^[16]^本文概述了**SIGHAN Bake-off 2013**上的中文拼写检查任务，描述了中文拼写检查任务的各个方面，包括任务描述，数据准备，性能指标和评估结果。本次测评有两个任务：错误检测和错误纠正。本次评测促使建立更多的中文资源，以便改进中文拼写检查的最先进技术，希望准备的数据集可以成为一个基准。

^[17]^本文概述了**NLPCC 2018**共享任务中的语法错误纠正任务。 我们对任务定义以及培训和评估数据进行了详细描述。 我们还总结了该任务参与者所研究的方法，对所有18种意见书进行了评估，针对中文语言的语法错误纠正是一项艰巨的任务，自动GEC系统和母语使用者之间仍然存在很大差距。

## 3 相关应用

**写作辅助**：在用户编辑文章的过程中，纠错服务能够及时发现用户错误行为，提升内容创作者的创作质量和效率。

**内容审核**：对于完稿的文章，纠错服务会对其标题和内容进行错误检测，由专业人员进行二次审核，保证文章质量，提升用户的阅读体验。

**场景纠错**：场景纠错除了做好语言规则的刻画和上下文理解外，还需要对场景中的领域知识有充分的学习。场景纠错的重点是针对输入数据做文本的理解、基于场景语料获取关联知识、基于大规模语料学习语言规则。场景纠错的应用点比如地图检索和语音对话。在地图检索业务中，通过充分利用 POI、位置距离特征及文本理解进行场景纠错，可以协助用户更好的找到目的地，改善用户体验。另一个场景纠错的应用场景是语音产品，语音的内容应该与当前环境场景相吻合，基于文本理解进行纠错。

## 4 参考文献

[1] H. T. Ng, S. M. Wu, T. Briscoe, and C. Hadiwinoto, “The conll- 2013 shared task on grammatical error correction.” in CoNLL Shared Task, **2013**, pp. 1–12.

[2] Ng H T, Wu S M, Briscoe T, et al. The CoNLL-2014 shared task on grammatical error correction[C]//Proceedings of the Eighteenth Conference on Computational Natural Language Learning: Shared Task. **2014**: 1-14.

[3] Wang C, Li R B, Lin H. Deep Context Model for Grammatical Error Correction[C]//SLaTE. **2017**: 167-171.

[4] Grundkiewicz R, Junczys-Dowmunt M. Near human-level performance in grammatical error correction with hybrid machine translation[J]. arXiv preprint arXiv:1804.05945, **2018**.

[5] Ge T, Wei F, Zhou M. Reaching human-level performance in automatic grammatical error correction: An empirical study[J]. arXiv preprint arXiv:1807.01270, **2018**.

[6] Lichtarge J, Alberti C, Kumar S, et al. Corpora Generation for Grammatical Error Correction[J]. arXiv preprint arXiv:1904.05780, **2019**.

[7] Bryant C, Briscoe T. Language model based grammatical error correction without annotated training data[C]//Proceedings of the Thirteenth Workshop on Innovative Use of NLP for Building Educational Applications. **2018**: 247-253.

[8] Yu C H, Chen H H. Detecting word ordering errors in Chinese sentences for learning Chinese as a foreign language[C]//Proceedings of COLING 2012. **2012**: 3003-3018.

[9] Wu S H, Liu C L, Lee L H. Chinese spelling check evaluation at SIGHAN Bake-off 2013[C]//Proceedings of the Seventh SIGHAN Workshop on Chinese Language Processing. **2013**: 35-42.

[10] Chang T H, Sung Y T, Hong J F, et al. KNGED: A tool for grammatical error diagnosis of Chinese sentences[C]//22nd International Conference on Computers in Education, ICCE. **2014**.

[11] Yu L C, Lee L H, Chang L P. Overview of grammatical error diagnosis for learning Chinese as a foreign language[C]//Proceedings of the 1st Workshop on Natural Language Processing Techniques for Educational Applications. **2014**: 42-47.

[12] Lung Hao Lee, Liang Chih Yu, and Li Ping Chang. 2015. Overview of the nlp-tea **2015** shared task for chinese grammatical error diagnosis. In Overview of the NLP-TEA 2015 Shared Task for Chinese Gram- matical Error Diagnosis.

[13] Lee L H, Gaoqi R A O, Yu L C, et al. Overview of nlp-tea 2016 shared task for chinese grammatical error diagnosis[C]//Proceedings of the 3rd Workshop on Natural Language Processing Techniques for Educational Applications (NLPTEA2016). **2016**: 40-48.

[14] Zheng B, Che W, Guo J, et al. Chinese grammatical error diagnosis with long short-term memory networks[C]//Proceedings of the 3rd Workshop on Natural Language Processing Techniques for Educational Applications (NLPTEA2016). **2016**: 49-56.

[15] Xie P. Alibaba at ijcnlp-2017 task 1: Embedding grammatical features into lstms for chinese grammatical error diagnosis task[C]//Proceedings of the IJCNLP **2017**, Shared Tasks. 2017: 41-46.

[16] Gaoqi R A O, Gong Q, Zhang B, et al. Overview of NLPTEA-2018 share task Chinese grammatical error diagnosis[C]//Proceedings of the 5th Workshop on Natural Language Processing Techniques for Educational Applications. **2018**: 42-51.

[17] Zhao Y, Jiang N, Sun W, et al. Overview of the nlpcc 2018 shared task: Grammatical error correction[C]//CCF International Conference on Natural Language Processing and Chinese Computing. Springer, Cham, **2018**: 439-445.

